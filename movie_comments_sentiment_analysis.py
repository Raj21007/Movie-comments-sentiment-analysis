# -*- coding: utf-8 -*-
"""Movie comments sentiment analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EDGTniaJ34U4ZKHHVEtTceVXi5J8OolY
"""

path=r"/content/IMDB Dataset.csv"

!pip install keras

import numpy as np
import pandas as pd
from tensorflow.keras.preprocessing.text import one_hot # Import from tensorflow.keras
from tensorflow.keras.preprocessing.sequence import pad_sequences

df=pd.read_csv(path,nrows=100)

df.head(10)

#replace
df["sentiment"].replace({"positive":1,"negative":0},inplace=True)
df.head(10)

x=np.array(df["review"].values)
y=np.array(df["sentiment"].values)

x_filtered=[]
for review in x:
  #lowering the sentence
  review=review.lower()
  #removing punctuations from sentence
  for i in review:
    punc=''' !()-[]{};:'"\,<>./?@#$%&*_~ '''
    if i in punc:
      review=review.replace(i, " ")
  # Append the modified review outside the inner loop
  x_filtered.append(review)

print(x_filtered)

#converting senetences to vectors
voc_size=5000
one_hot_encoded=[one_hot(review,voc_size)for review in x_filtered]
print(one_hot_encoded)

# Find the maximum length of the one-hot encoded reviews
max_length = max(len(review) for review in one_hot_encoded)

#padding sentences to the maximum length
x_padded=pad_sequences(one_hot_encoded,max_length,padding="post")

#splitting the dataset
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x_padded,y,test_size=0.3)

#model creation
from keras.models import Sequential
from keras.layers import Dense, LSTM, Embedding
import numpy as np

# Define the parameters
voc_size = 5000  # Example vocab size
embedded_vector_size = 35
max_length = 100  # Example max length

# Define the model
model = Sequential()
model.add(Embedding(voc_size, embedded_vector_size))  # Removed input_length
model.add(LSTM(100))
model.add(Dense(1, activation="sigmoid"))

# Build the model
model.build(input_shape=(None, max_length))

# Print the summary
print(model.summary())

#training the model
model.compile(loss="binary_crossentropy",metrics=["accuracy"]) # Corrected loss function name
model.fit(x_train,y_train,epochs=10)

score=model.evaluate(x_test,y_test)
print("ACCURACY : ",score)

# saving the model
model.save("IMDB_Sentiment_Analysis.keras") # Add the .keras extension

#loading the model
from tensorflow.keras.models import load_model
trained_model=load_model("/content/IMDB_Sentiment_Analysis.keras")

def get_sentiment(sentence: str):
    if isinstance(sentence, (str)):
        pass
    else:
        raise Exception("Input needs to be of type 'str' ")

    # filtering the sentence
    sentence = sentence.lower()

    punc = '''!()-[]{};:'"\, <>./?@#$%^&*_~'''

    for word in sentence:
        if word in punc:
            sentence = sentence.replace(word, " ")

    # Loading the saved trained model.
    # Removed redundant import and load_model call here, as it is already done above

    predicted = trained_model.predict(x_test)[2] # Assuming x_test is defined somewhere
    sentiment = 1 if predicted > 0.6 else 0

    if sentiment == 1:
        print("Positive")
    else:
        print("Negative")

    return sentiment

result=get_sentiment("that movie was good!")
print(result)